# PR Pilot - Learning Notes

This document tracks what we learn as we build this project together.

## Sprint 0: Project Setup

### âœ… What We've Done
- Created project structure with backend/, worker/, infra/, tests/, docs/
- Understood why we separate webhook receiver from worker (speed vs. heavy processing)

### ðŸŽ“ Key Concepts Learned

#### Why Separate Backend & Worker?
- **Backend (FastAPI)**: Must respond to webhooks in < 10 seconds or GitHub retries
- **Worker (Celery)**: Can take 30+ seconds to do AI processing
- **Pattern**: Receive â†’ Acknowledge â†’ Process Async

#### The Message Queue Pattern
```
GitHub â†’ FastAPI â†’ Redis Queue â†’ Celery Worker â†’ Post Comment Back
         (instant)                  (slow AI work)
```

### ðŸ“ Completed Sprint 0
- [x] Install Python dependencies (FastAPI, Celery, PyGithub, HuggingFace Hub)
- [x] Test FastAPI locally
- [x] Set up Docker Compose (Postgres + Redis)
- [x] Build webhook endpoint with signature verification
- [x] Set up Celery worker
- [x] Connect webhook to Celery task queue

### ðŸŽ¯ Current Status
We have built the complete pipeline:
```
GitHub Webhook â†’ FastAPI â†’ Redis Queue â†’ Celery Worker
```

### ðŸ“ Completed Sprint 1 âœ…
- [x] Test end-to-end flow
- [x] Integrate HuggingFace models for PR summarization
- [x] Parse PR diffs
- [x] Post comments back to GitHub
- [x] GitHub API integration (fetch PRs, post comments)
- [x] AI-powered summarization with fallbacks
- [x] PR classification (bug/feature/refactor/docs)
- [x] Risk detection and suggestions
- [x] Commit message generation

### ðŸŽ¯ What We Built (Sprint 0 + Sprint 1)

**Complete Pipeline:**
```
GitHub Webhook â†’ FastAPI â†’ Redis â†’ Celery Worker â†’ AI Analysis â†’ GitHub Comment
```

**Features:**
1. âœ… Webhook endpoint with HMAC signature verification
2. âœ… Async job processing with Celery + Redis
3. âœ… GitHub integration (fetch diffs, post comments)
4. âœ… HuggingFace AI integration (summarization, classification)
5. âœ… Smart fallbacks when AI is unavailable
6. âœ… Risk detection (large PRs, sensitive files)
7. âœ… Test/doc suggestions
8. âœ… Conventional commit message generation
9. âœ… Beautiful markdown comment formatting

**Tech Stack:**
- Backend: FastAPI, Python 3.13
- Worker: Celery, Redis
- Database: PostgreSQL (with pgvector for future)
- AI: HuggingFace Inference API
- Infrastructure: Docker Compose

### ðŸ“ Next Steps (Future Sprints)
- [ ] Interactive commands (@PR-Pilot /review)
- [ ] Inline code suggestions
- [ ] Database models for storing analysis history
- [ ] User feedback collection
- [ ] Dashboard for viewing results
- [ ] Support for GitLab/BitBucket

---

## Questions & Answers

### Q: Why Redis instead of just calling the worker directly?
A: Redis provides:
1. **Buffering**: If 10 PRs open at once, queue them
2. **Reliability**: If worker crashes, jobs aren't lost
3. **Retry Logic**: Failed jobs can retry automatically
4. **Scaling**: Can add more workers to process faster

### Q: Could we use a single service instead of two?
A: Yes, but you'd hit GitHub's timeout limits. Separating concerns = better architecture.

---

*Keep adding notes as you learn! This becomes your personal reference.*

